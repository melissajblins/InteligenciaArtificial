# -*- coding: utf-8 -*-
"""Pratica4_IA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fmaI6mZJ-JZ9dYdqHNFqg0VIFbPu6j-A

# Prática 4 - Inteligência Artificial


1. Implementar o Naive Bayes Wrapper
2. Testar com a Iris e alguma outra base de dados

---
**Nome**: Melissa Junqueira de Barros Lins

**RA**: 11201920583

---

## Código base
"""

#Importando bibliotecas
import numpy as np
from sklearn.datasets import load_iris
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split

X, y = load_iris(return_X_y = True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)

exp = GaussianNB()
exp.fit(X_train, y_train)
y_pred = exp.predict(X_test)
print("Acertou {} de {}\n".format((y_pred == y_test).sum(), X_test.shape[0]))

#Mostrando as probabilidades de predição junto com as classes corretas
class_prob = np.round(exp.predict_proba(X_test),2)
print((np.column_stack((class_prob, y_test))))

#Gerando  NB com apenas a 1ª característica
#O reshape é necessário para transformar o vetor em uma matriz de 1 coluna
exp = exp.fit(X_train[:,0].reshape(-1, 1), y_train)
y_pred = exp.predict(X_test[:,0].reshape(-1,1))
print("\n")
print(y_pred)
print("\nAcertou {} de {}".format((y_pred == y_test).sum(), X_test.shape[0]))

"""## Testes com numpy

```
#Criando uma matriz de 2 linhas e 3 colunas
mat = np.array([[1, 2, 3], [4, 5, 6]])

#Acessando apenas 1 linha da matriz
mat[1,:]

#Acessando apenas 1 coluna da matriz
mat[:,1]

#Transpondo a matriz
mat.transpose()

#Contatenando uma coluna à matriz
col = [7, 8]
np.column_stack(mat, col)

#Concatenando uma linha à matriz
row = [7, 8, 9]
np.row_stack((mat, row))

#Acessando o nro de linhas e colunas da matriz
mat.shape
  
  ```

## Implementando Naive Bayes Wrapper com Iris Database
"""

#Carregando Iris e distribuindo treino-teste
X, y = load_iris(return_X_y = True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)
exp = GaussianNB()

#Calculando os acertos
print("=== Teste 1 ===")
for i in range(4):
  print("{}ª Característica".format(i+1))
  exp = exp.fit(X_train[:,i].reshape(-1, 1), y_train)
  y_pred = exp.predict(X_test[:,i].reshape(-1,1))
  acertos = (y_pred == y_test).sum()
  print("Acertou {} de {}\n".format(acertos, X_test.shape[0]))
  vetor_acertos_vs4.append(acertos)
  if i == 0:
    maior = acertos
    indexmaior = i
  elif acertos > maior:
    maior = acertos
    indexmaior = i

#Criando as matrizes e calculando os acertos
print("=== Teste 2 ===")
contador_testes = 0
for i in range(4):
  if i != indexmaior:
    treino = np.column_stack((X_train[:,indexmaior].reshape(-1, 1), X_train[:,i].reshape(-1, 1)))
    teste = np.column_stack((X_test[:,indexmaior].reshape(-1, 1), X_test[:,i].reshape(-1, 1)))
    print("{}ª e {}ª Características".format(indexmaior + 1, i + 1))
    exp = exp.fit(treino, y_train)
    y_pred = exp.predict(teste)
    acertos = (y_pred == y_test).sum()
    print("Acertou {} de {}\n".format(acertos, X_test.shape[0]))
    if contador_testes == 0:
      maior = acertos
      indexintermediario = i
    elif acertos > maior:
      maior = acertos
      indexintermediario = i
    contador_testes = contador_testes + 1

#Criando as matrizes e calculando os acertos
print("=== Teste 3 ===")
contador_testes = 0
for i in range(4):
  if i != indexmaior and i != indexintermediario:
    treino = np.column_stack((X_train[:,indexmaior].reshape(-1, 1), X_train[:,indexintermediario].reshape(-1, 1), X_train[:,i].reshape(-1, 1)))
    teste = np.column_stack((X_test[:,indexmaior].reshape(-1, 1), X_test[:,indexintermediario].reshape(-1, 1), X_test[:,i].reshape(-1, 1)))
    print("{}ª, {}ª e {}ª Características".format(indexmaior + 1, indexintermediario + 1, i + 1))
    exp = exp.fit(treino, y_train)
    y_pred = exp.predict(teste)
    acertos = (y_pred == y_test).sum()
    print("Acertou {} de {}\n".format(acertos, X_test.shape[0]))
    if contador_testes == 0:
      maior = acertos
      indexterceiro = i
    elif acertos > maior:
      maior = acertos
      indexterceiro = i
    contador_testes = contador_testes + 1

#Criando as matrizes e calculando os acertos
print("=== Teste 4 ===")
contador_testes = 0
for i in range(4):
  if i != indexmaior and i != indexintermediario and i != indexterceiro:
    treino = np.column_stack((X_train[:,indexmaior].reshape(-1, 1), X_train[:,indexintermediario].reshape(-1, 1), X_train[:,indexterceiro].reshape(-1, 1), X_train[:,i].reshape(-1, 1) ))
    teste = np.column_stack((X_test[:,indexmaior].reshape(-1, 1), X_test[:,indexintermediario].reshape(-1, 1), X_test[:,indexterceiro].reshape(-1, 1), X_test[:,i].reshape(-1, 1)))
    print("{}ª, {}ª, {}ª e {}ª Características".format(indexmaior + 1, indexintermediario + 1, indexterceiro + 1, i + 1))
    exp = exp.fit(treino, y_train)
    y_pred = exp.predict(teste)
    acertos = (y_pred == y_test).sum()
    print("Acertou {} de {}\n".format(acertos, X_test.shape[0]))

"""### Anotações
Percebemos que usando somente as duas características com mais acertos é possível obter uma grande taxa de acurácia final.



"""